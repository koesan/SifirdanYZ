{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a96290",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import struct\n",
    "import time\n",
    "import pygame\n",
    "from IPython.display import clear_output, display "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d92db26",
   "metadata": {},
   "source": [
    "# MNIST Veri Seti ve MLP GiriÅŸ FormatÄ±\n",
    "\n",
    "MNIST veri setinde **orijinal format**, her satÄ±rÄ±n bir Ã¶rneÄŸi temsil ettiÄŸi bir tablo ÅŸeklindedir:\n",
    "\n",
    "- **SatÄ±rlar** â†’ Ã¶rnekler (resimler)  \n",
    "- **SÃ¼tunlar** â†’ her Ã¶rneÄŸin piksel deÄŸerleri  \n",
    "\n",
    "Ã–rneÄŸin: `images.shape = (10000, 784)`  \n",
    "- 10.000 resim  \n",
    "- Her resimde 784 piksel\n",
    "\n",
    "---\n",
    "\n",
    "Ancak **MLP (Ã§ok katmanlÄ± algÄ±layÄ±cÄ±)** gibi yapay sinir aÄŸlarÄ±, **giriÅŸ verisini `(Ã¶zellik sayÄ±sÄ±, Ã¶rnek sayÄ±sÄ±)` formatÄ±nda** bekler:\n",
    "\n",
    "- **SatÄ±rlar** â†’ Ã¶zellikler (her piksel bir Ã¶zellik)  \n",
    "- **SÃ¼tunlar** â†’ Ã¶rnekler (her sÃ¼tun bir resim)\n",
    "\n",
    "Bu nedenle `images.T` (transpose) kullanÄ±larak verinin satÄ±r ve sÃ¼tunlarÄ± yer deÄŸiÅŸtirildi. SonuÃ§ olarak:\n",
    "\n",
    "- Her sÃ¼tun artÄ±k bir Ã¶rnek resim  \n",
    "- Her satÄ±r bir pikseli temsil ediyor\n",
    "\n",
    "Bu dÃ¶nÃ¼ÅŸÃ¼m sayesinde, aÄŸÄ±rlÄ±k matrisi ile giriÅŸ matrisinin Ã§arpÄ±mÄ± **boyut olarak uyumlu** oluyor ve MLP doÄŸru ÅŸekilde Ã§alÄ±ÅŸabiliyor.\n",
    "\n",
    "---\n",
    "\n",
    "**Ã–zetle:**\n",
    "\n",
    "> MNISTâ€™in satÄ±r-temelli formatÄ±nÄ±, MLPâ€™nin ihtiyaÃ§ duyduÄŸu sÃ¼tun-temelli formata Ã§evirdik.  \n",
    "> BÃ¶ylece matris Ã§arpÄ±mlarÄ± sorunsuz gerÃ§ekleÅŸiyor ve her sÃ¼tun baÄŸÄ±msÄ±z bir Ã¶rnek olarak aÄŸ tarafÄ±ndan iÅŸlenebiliyor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST resim dosyasÄ±nÄ± (el yazÄ±sÄ± rakamlar) okuyan fonksiyon.\n",
    "def load_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # DosyanÄ±n baÅŸÄ±ndan resim sayÄ±sÄ±nÄ±, satÄ±r ve sÃ¼tun sayÄ±sÄ±nÄ± okuyoruz.\n",
    "        # \">IIII\": Bu bir okuma formatÄ±dÄ±r.\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "\n",
    "        # Geri kalan tÃ¼m veriyi resim pikselleri olarak alÄ±yoruz (0-255 arasÄ± parlaklÄ±k).\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "        # Her resmi (28x28) tek bir uzun satÄ±r (784 piksel) haline getiriyoruz.\n",
    "        images = images.reshape(num, rows*cols)\n",
    "        return images\n",
    "\n",
    "# MNIST etiket dosyasÄ±nÄ± (resmin hangi rakam olduÄŸunu) okuyan fonksiyon.\n",
    "def load_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # DosyanÄ±n baÅŸÄ±ndan etiket sayÄ±sÄ±nÄ± okuyoruz.\n",
    "        # \">II\": Bu da bir okuma formatÄ±dÄ±r.\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "\n",
    "        # Geri kalan tÃ¼m veriyi resimlerin rakamlarÄ± (etiketleri) olarak alÄ±yoruz.\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "# --- Veriyi YÃ¼klÃ¼yoruz ---\n",
    "\n",
    "# Resim dosyalarÄ±nÄ± ve etiket dosyalarÄ±nÄ± yÃ¼klÃ¼yoruz.\n",
    "images = load_mnist_images(\"./t10k-images.idx3-ubyte\")\n",
    "labels = load_mnist_labels(\"./t10k-labels.idx1-ubyte\")\n",
    "\n",
    "# YÃ¼klenen resim ve etiketlerin kaÃ§ar tane olduÄŸunu gÃ¶ster.\n",
    "print(images.shape)  # Ã‡Ä±ktÄ±: (10000, 784) -> 10000 resim, her biri 784 piksel\n",
    "print(labels.shape)  # Ã‡Ä±ktÄ±: (10000,) -> 10000 etiket\n",
    "\n",
    "## Veriyi EÄŸitim ve Test GruplarÄ±na AyÄ±rma âœ‚ï¸\n",
    "# Modeli eÄŸitmek ve ne kadar iyi Ã¶ÄŸrendiÄŸini test etmek iÃ§in veriyi ayÄ±rÄ±yoruz.\n",
    "# Ä°lk 1000 tanesi \"Test\", geri kalanÄ± \"EÄŸitim\" iÃ§in kullanÄ±lacak.\n",
    "\n",
    "# TEST VERÄ°SÄ° (Modeli denemek iÃ§in)\n",
    "# Ä°lk 1000 resim ve etiketini al.\n",
    "x_test = images[:1000].T # Resimleri al ve satÄ±r-sÃ¼tun yerini deÄŸiÅŸtir (.T)\n",
    "\n",
    "# Piksel deÄŸerlerini (0-255) 255'e bÃ¶lerek 0 ile 1 arasÄ±na getir (NormalleÅŸtirme).\n",
    "# Bu, modelin daha hÄ±zlÄ± Ã¶ÄŸrenmesini saÄŸlar.\n",
    "x_test = x_test/255.\n",
    "y_test = labels[:1000]\n",
    "\n",
    "# EÄžÄ°TÄ°M VERÄ°SÄ° (Modeli eÄŸitmek iÃ§in)\n",
    "# Kalan tÃ¼m resim ve etiketleri al (1000. sÄ±radan sonrasÄ±).\n",
    "x_train = images[1000:].T\n",
    "x_train = x_train/255. # Yine normalleÅŸtirme yap.\n",
    "y_train = labels[1000:]\n",
    "\n",
    "# Son olarak, oluÅŸan gruplarÄ±n boyutlarÄ±nÄ± kontrol et.\n",
    "print(x_train.shape) # EÄŸitim resimlerinin yeni boyutu\n",
    "print(y_train.shape) # EÄŸitim etiketlerinin yeni boyutu\n",
    "print(x_test.shape)  # Test resimlerinin yeni boyutu\n",
    "print(y_test.shape)  # Test etiketlerinin yeni boyutu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32468e46",
   "metadata": {},
   "source": [
    "# AÃ§Ä±klama: MLP Parametreleri, Ä°leri ve Geri YayÄ±lÄ±m\n",
    "\n",
    "Bu bÃ¶lÃ¼mde, Ã§ok katmanlÄ± bir algÄ±layÄ±cÄ± (MLP) iÃ§in temel adÄ±mlarÄ± gÃ¶rÃ¼yoruz:\n",
    "\n",
    "1. **Parametrelerin BaÅŸlatÄ±lmasÄ± (`init_params`)**\n",
    "\n",
    "   * AÄŸÄ±rlÄ±klar rastgele kÃ¼Ã§Ã¼k deÄŸerlerle baÅŸlatÄ±lÄ±yor.\n",
    "   * Biaslar da rastgele seÃ§iliyor.\n",
    "   * Katman boyutlarÄ± giriÅŸten Ã§Ä±kÄ±ÅŸa doÄŸru tanÄ±mlanÄ±yor: 784 â†’ 128 â†’ 64 â†’ 32 â†’ 10\n",
    "\n",
    "2. **Aktivasyon FonksiyonlarÄ± (`relu` ve `softmax`)**\n",
    "\n",
    "   * `relu`: Negatif deÄŸerleri 0â€™a Ã§eviriyor, pozitifleri olduÄŸu gibi bÄ±rakÄ±yor.\n",
    "   * `relu_deriv`: Backprop sÄ±rasÄ±nda kullanÄ±lÄ±yor, sadece aktif nÃ¶ronlarÄ±n gradini geÃ§iriyor.\n",
    "   * `softmax`: Ã‡Ä±kÄ±ÅŸ katmanÄ± iÃ§in olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± oluÅŸturuyor, tÃ¼m olasÄ±lÄ±klarÄ±n toplamÄ± 1 oluyor.\n",
    "\n",
    "3. **Ä°leri YayÄ±lÄ±m (`forward_prop`)**\n",
    "\n",
    "   * GiriÅŸ verisi katman katman iÅŸleniyor.\n",
    "   * Her katmanda aÄŸÄ±rlÄ±klÄ± toplam + bias hesaplanÄ±yor, aktivasyon fonksiyonuna gÃ¶nderiliyor.\n",
    "   * Ã‡Ä±kÄ±ÅŸta softmax ile tahmin olasÄ±lÄ±klarÄ± elde ediliyor.\n",
    "\n",
    "4. **One-Hot Kodlama (`one_hot`)**\n",
    "\n",
    "   * Etiketleri sinir aÄŸÄ±nÄ±n anlayacaÄŸÄ± forma Ã§eviriyoruz.\n",
    "   * Ã–rneÄŸin, \"3\" etiketi â†’ `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`\n",
    "\n",
    "5. **Geri YayÄ±lÄ±m (`backward_prop`)**\n",
    "\n",
    "   * Hata, Ã§Ä±kÄ±ÅŸtan giriÅŸe doÄŸru katman katman aktarÄ±lÄ±yor.\n",
    "   * Her katman iÃ§in aÄŸÄ±rlÄ±k ve bias gradyanlarÄ± hesaplanÄ±yor.\n",
    "   * `relu_deriv` ile sadece aktif nÃ¶ronlar iÃ§in gradyan geÃ§iyor.\n",
    "\n",
    "6. **Parametre GÃ¼ncelleme (`update_params`)**\n",
    "\n",
    "   * Hesaplanan gradyanlara gÃ¶re aÄŸÄ±rlÄ±k ve biaslar gÃ¼ncelleniyor.\n",
    "   * Ã–ÄŸrenme oranÄ± (`alpha`) ile ne kadar deÄŸiÅŸiklik yapÄ±lacaÄŸÄ±nÄ± kontrol ediyoruz.\n",
    "\n",
    "> KÄ±saca: Bu kod, MLPâ€™nin temel dÃ¶ngÃ¼sÃ¼nÃ¼ oluÅŸturuyor. Ä°leri yayÄ±lÄ±m tahmin yapÄ±yor, geri yayÄ±lÄ±m hatayÄ± hesaplÄ±yor ve parametreleri gÃ¼ncelleyerek modelin Ã¶ÄŸrenmesini saÄŸlÄ±yor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149657b2",
   "metadata": {},
   "source": [
    "# Aktivasyon Fonksiyonu: ReLU (Rectified Linear Unit)\n",
    "\n",
    "## ReLU Neden KullanÄ±lÄ±r ve Ne Ä°ÅŸe Yarar?\n",
    "\n",
    "Yapay sinir aÄŸlarÄ±nda, bir katmandan gelen Ã§Ä±ktÄ±larÄ± bir sonraki katmana iletmeden Ã¶nce bir **Aktivasyon Fonksiyonundan** geÃ§iririz.\n",
    "\n",
    "**ReLU (DÃ¼zeltilmiÅŸ DoÄŸrusal Birim)**, bu fonksiyonlar arasÄ±nda en popÃ¼ler olanÄ±dÄ±r. Temel amacÄ±, sinir aÄŸÄ±na **doÄŸrusallÄ±k dÄ±ÅŸÄ± (non-linearity)** Ã¶zellik katmaktÄ±r. Bu Ã¶zellik olmadan, aÄŸ ne kadar derin olursa olsun (ne kadar katman eklerseniz ekleyin), sadece dÃ¼z bir Ã§izgi (lineer bir denklem) Ã§izebilir.\n",
    "\n",
    "ReLU, basitliÄŸi sayesinde:\n",
    "\n",
    "1.  **Hesaplama HÄ±zÄ±:** Ã‡ok hÄ±zlÄ± ve kolay hesaplanÄ±r.\n",
    "2.  **Seyreklik (Sparsity):** Negatif deÄŸerleri sÄ±fÄ±rlayarak aÄŸÄ±n seyrekleÅŸmesini saÄŸlar, bu da Ã¶ÄŸrenmeyi kolaylaÅŸtÄ±rÄ±r.\n",
    "\n",
    "-----\n",
    "\n",
    "## 1\\. ReLU Fonksiyonu (Ä°leri YayÄ±lÄ±m)\n",
    "\n",
    "ReLU, giriÅŸ deÄŸeri ($x$) iÃ§in basit bir kural uygular: **EÄŸer giriÅŸ pozitifse, olduÄŸu gibi geÃ§ir; eÄŸer negatifse, sÄ±fÄ±r yap.**\n",
    "\n",
    "**Matematiksel TanÄ±m:**\n",
    "\n",
    "$$\\operatorname {ReLU} (x)= \\max(0,x)$$\n",
    "\n",
    "Veya ParÃ§alÄ± Fonksiyon Olarak:\n",
    "\n",
    "$$\\operatorname{ReLU} (x)= {\\begin{cases}x&{\\text{if }}x>0,\\\\0&x\\leq 0\\end{cases}}$$\n",
    "\n",
    "**Python Kodu ile UygulanÄ±ÅŸÄ±:**\n",
    "\n",
    "```python\n",
    "def relu(X):\n",
    "    # X'teki her elemanÄ± 0 ile karÅŸÄ±laÅŸtÄ±rÄ±r ve bÃ¼yÃ¼k olanÄ± dÃ¶ndÃ¼rÃ¼r.\n",
    "    return np.maximum(X, 0)\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "## 2\\. ReLU TÃ¼revi (Geri YayÄ±lÄ±m - Backpropagation)\n",
    "\n",
    "Sinir aÄŸÄ±nÄ±n Ã¶ÄŸrenmesi (aÄŸÄ±rlÄ±klarÄ±n gÃ¼ncellenmesi) **Geri YayÄ±lÄ±m (Backpropagation)** ile gerÃ§ekleÅŸir. Bu sÃ¼reÃ§te, hatanÄ±n geriye doÄŸru yayÄ±lmasÄ± iÃ§in aktivasyon fonksiyonunun **tÃ¼revine** ihtiyacÄ±mÄ±z vardÄ±r.\n",
    "\n",
    "**ReLU'nun TÃ¼revi** de tÄ±pkÄ± kendisi gibi Ã§ok basittir: **GiriÅŸ pozitifse 1, negatif veya sÄ±fÄ±rsa 0.**\n",
    "\n",
    "**Matematiksel TÃ¼rev TanÄ±mÄ±:**\n",
    "\n",
    "$$\\operatorname{ReLU}'(x) = {\\begin{cases}1 & \\text{if } x > 0 \\\\0 & \\text{if } x \\le 0\\end{cases}}$$\n",
    "\n",
    "**Python Kodu ile UygulanÄ±ÅŸÄ±:**\n",
    "\n",
    "```python\n",
    "def relu_deriv(Z):\n",
    "    # Python'da True=1, False=0 demektir.\n",
    "    # Bu ifade, Z'nin pozitif olduÄŸu yerlerde 1, diÄŸer yerlerde 0 dÃ¶ndÃ¼rÃ¼r.\n",
    "    return Z > 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9171837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return np.maximum(X, 0)\n",
    "\n",
    "def relu_deriv(Z):\n",
    "    return Z > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa79778",
   "metadata": {},
   "source": [
    "# Softmax: SonuÃ§larÄ± OlasÄ±lÄ±klara Ã‡evir\\!\n",
    "\n",
    "## Softmax Ne Yapar ve Neden LazÄ±m?\n",
    "\n",
    "Yapay zeka modelimiz bir resme baktÄ±ktan sonra, her bir rakam iÃ§in bir \"gÃ¼ven puanÄ±\" verir. Softmax'Ä±n gÃ¶revi, bu ham puanlarÄ± alÄ±p, bizim anlayacaÄŸÄ±mÄ±z **kesin olasÄ±lÄ±klara** Ã§evirmektir.\n",
    "\n",
    "  * **GÃ¶revi:** Modelin tahminlerini, toplamÄ± **%100 (yani 1)** olan olasÄ±lÄ±klara dÃ¶nÃ¼ÅŸtÃ¼rmek.\n",
    "  * **SonuÃ§:** Modelin hangi sÄ±nÄ±fa ne kadar inandÄ±ÄŸÄ±nÄ± net bir ÅŸekilde gÃ¶sterir.\n",
    "\n",
    "**Ã–rnek:** Modelin \"7\" olma puanÄ± yÃ¼ksekse, Softmax o Ã§Ä±ktÄ±ya en bÃ¼yÃ¼k olasÄ±lÄ±ÄŸÄ± (%90 gibi) verir.\n",
    "\n",
    "-----\n",
    "\n",
    "## 1\\. Softmax Fonksiyonu (Hesaplama AdÄ±mÄ±)\n",
    "\n",
    "Softmax, yÃ¼ksek puana sahip olanÄ± diÄŸerlerine gÃ¶re Ã§ok daha fazla Ã¶ne Ã§Ä±karÄ±r.\n",
    "\n",
    "**Matematiksel FormÃ¼l:**\n",
    "\n",
    "$$\\sigma (\\mathbf {z} )_{i}={\\frac {e^{z_{i}}}{\\sum _{j=1}^{K}e^{z_{j}}}}$$\n",
    "\n",
    "  * **$z_i$**: SÄ±nÄ±f $i$'nin (Ã¶rneÄŸin rakam 7'nin) aldÄ±ÄŸÄ± ham puandÄ±r.\n",
    "  * **$e^{z_i}$**: PuanÄ±n kuvveti alÄ±narak pozitif yapÄ±lÄ±r ve deÄŸeri bÃ¼yÃ¼tÃ¼lÃ¼r (gÃ¼Ã§lendirilir).\n",
    "  * **$\\sum _{j=1}^{K}e^{z_{j}}$**: TÃ¼m sÄ±nÄ±flarÄ±n ($K$ tane) gÃ¼Ã§lendirilmiÅŸ puanlarÄ±nÄ±n toplamÄ±dÄ±r (payda).\n",
    "\n",
    "**âš ï¸ Ã–nemli Not (KararlÄ±lÄ±k):**\n",
    "Kodda gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z `np.max(X)` Ã§Ä±karma iÅŸlemi, bÃ¼yÃ¼k puanlar nedeniyle bilgisayarÄ±n hata vermesini (sayÄ±nÄ±n sonsuza ulaÅŸmasÄ±nÄ±) engellemek iÃ§in yapÄ±lÄ±r. Bu, formÃ¼lÃ¼n pratik uygulamada **daha gÃ¼venli** Ã§alÄ±ÅŸmasÄ± iÃ§in bir hiledir\\! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24482b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    e_x = np.exp(X - np.max(X))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100e161",
   "metadata": {},
   "source": [
    "# One-Hot Encoding:\\!\n",
    "\n",
    "## Bu Fonksiyon Neden Gerekli?\n",
    "\n",
    "Yapay zeka modelimiz (sinir aÄŸÄ±mÄ±z), tahmin yaparken Ã§Ä±ktÄ± olarak 10 farklÄ± nÃ¶ron kullanÄ±r (her biri 0'dan 9'a kadar bir rakam iÃ§in).\n",
    "\n",
    "Bizim elimizdeki etiketler ise sadece tek bir sayÄ±dÄ±r. Ã–rneÄŸin, \"Bu resim **7**\" veya \"Bu resim **3**\".\n",
    "\n",
    "**Problem:** EÄŸer modele sadece \"7\" dersek, model bu sayÄ±yÄ± **bir deÄŸer** olarak algÄ±lar. Yani yanlÄ±ÅŸlÄ±kla 7'nin 1'den 7 kat daha Ã¶nemli olduÄŸunu dÃ¼ÅŸÃ¼nebilir. ðŸ™…â€â™€ï¸\n",
    "\n",
    "**One-Hot Ã‡Ã¶zÃ¼mÃ¼:** Bu fonksiyon, elimizdeki tek sayÄ±yÄ±, iÃ§inde sadece **bir tane 1** olan uzun bir \"cevap kartÄ±na\" Ã§evirir.\n",
    "\n",
    "| Orijinal Etiket | Cevap KartÄ± (10 Kutucuk) | AnlamÄ± |\n",
    "| :---: | :---: | :--- |\n",
    "| **3** | `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]` | 3. kutucukta **EVET (1)** var. DiÄŸerleri HAYIR (0). |\n",
    "| **7** | `[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]` | 7. kutucukta **EVET (1)** var. |\n",
    "\n",
    "Bu sayede model, \"3\" ve \"7\"nin sadece **farklÄ± seÃ§enekler** olduÄŸunu anlar. âœ…\n",
    "\n",
    "-----\n",
    "\n",
    "## 1\\. One-Hot Fonksiyonu (AdÄ±m AdÄ±m Kodlama)\n",
    "\n",
    "Bu kod, etiketleri ($Y$), modelin eÄŸitilmesi iÃ§in uygun olan **cevap kartÄ±** formatÄ±na Ã§evirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y):\n",
    "    # 1. SÄ±fÄ±rlardan oluÅŸan bir matris oluÅŸtur\n",
    "    # (Y.size: Ã¶rnek sayÄ±sÄ±, Y.max() + 1: sÄ±nÄ±f sayÄ±sÄ± (0'dan baÅŸladÄ±ÄŸÄ± iÃ§in +1))\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    \n",
    "    # 2. KarÅŸÄ±lÄ±k gelen sÃ¼tunlara 1 deÄŸerini atama\n",
    "    # Y.size: tÃ¼m satÄ±rlarÄ± seÃ§\n",
    "    # Y: her satÄ±r iÃ§in hangi sÃ¼tunun 1 olacaÄŸÄ±nÄ± belirler\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    \n",
    "    # 3. BoyutlarÄ± sinir aÄŸÄ±na uygun hale getirme (Transpoze)\n",
    "    # (SÄ±nÄ±f sayÄ±sÄ± x Ã–rnek sayÄ±sÄ±\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "\n",
    "    return one_hot_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b238d98",
   "metadata": {},
   "source": [
    "# init\\_params():\n",
    "\n",
    "## Bu Fonksiyon Ne Yapar?\n",
    "\n",
    "Bir yapay sinir aÄŸÄ±, Ã¶ÄŸrenmeye baÅŸlamadan Ã¶nce **aÄŸÄ±rlÄ±klara (W)** ve **sapmalara (b)** ihtiyaÃ§ duyar. Bunlar, aÄŸÄ±n bir katmandan diÄŸerine bilgi taÅŸÄ±rken kullanacaÄŸÄ± temel sayÄ±lardÄ±r.\n",
    "\n",
    "  * **AÄŸÄ±rlÄ±klar (W):** GiriÅŸ verisinden gelen her bilginin **Ã¶nemini** belirleyen sayÄ±lardÄ±r (Matris).\n",
    "  * **Sapmalar (b):** Her nÃ¶ronun tek baÅŸÄ±na Ã¼rettiÄŸi **ekstra bir deÄŸerdir** (VektÃ¶r).\n",
    "\n",
    "Bu fonksiyon, bu aÄŸÄ±rlÄ±k ve sapmalarÄ± **rastgele** sayÄ±larla baÅŸlatÄ±r.\n",
    "\n",
    "## AÄŸÄ±mÄ±zÄ±n YapÄ±sÄ± (4 KatmanlÄ±)\n",
    "\n",
    "Modelimiz 4 katmandan oluÅŸmaktadÄ±r. Her katman, bir Ã¶nceki katmandan gelen bilgiyi iÅŸler:\n",
    "\n",
    "| Katman | GiriÅŸ NÃ¶ronu | Ã‡Ä±kÄ±ÅŸ NÃ¶ronu | AmacÄ± |\n",
    "| :---: | :---: | :---: | :--- |\n",
    "| **GiriÅŸ** | 784 | - | Her resimdeki 784 piksel. |\n",
    "| **Gizli 1** | 784 | 128 | Veriyi kÃ¼Ã§Ã¼ltmeye baÅŸlar. |\n",
    "| **Gizli 2** | 128 | 64 | Daha fazla desen Ã¶ÄŸrenir. |\n",
    "| **Gizli 3** | 64 | 32 | En karmaÅŸÄ±k desenleri Ã§Ä±karÄ±r. |\n",
    "| **Ã‡Ä±kÄ±ÅŸ** | 32 | **10** | SonuÃ§ta 0'dan 9'a kadar 10 sÄ±nÄ±fÄ± tahmin eder. |\n",
    "\n",
    "-----\n",
    "\n",
    "## 1\\. init\\_params Fonksiyonu (BaÅŸlatma)\n",
    "\n",
    "Bu kod, her bir katmanÄ±n aÄŸÄ±rlÄ±k (W) ve sapma (b) matrislerini rastgele sayÄ±larla doldurur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e1e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    \n",
    "    # ðŸ“ Not: np.random.rand(...) - 0.5 kullanmamÄ±zÄ±n sebebi,\n",
    "    # aÄŸÄ±rlÄ±klarÄ±n hem pozitif hem de negatif sayÄ±larla baÅŸlamasÄ±nÄ± saÄŸlamaktÄ±r.\n",
    "\n",
    "    # ðŸ‘‰ Gizli Katman 1: 784 pikseli 128 nÃ¶rona baÄŸlar\n",
    "    W1 = np.random.rand(128, 784) - 0.5 # W1: (128 satÄ±r, 784 sÃ¼tun)\n",
    "    b1 = np.random.rand(128, 1) - 0.5  # b1: (128 satÄ±r, 1 sÃ¼tun)\n",
    "    \n",
    "    # ðŸ‘‰ Gizli Katman 2: 128 nÃ¶ronu 64 nÃ¶rona baÄŸlar\n",
    "    W2 = np.random.rand(64, 128) - 0.5 # W2: (64 satÄ±r, 128 sÃ¼tun)\n",
    "    b2 = np.random.rand(64, 1) - 0.5   # b2: (64 satÄ±r, 1 sÃ¼tun)\n",
    "    \n",
    "    # ðŸ‘‰ Gizli Katman 3: 64 nÃ¶ronu 32 nÃ¶rona baÄŸlar\n",
    "    W3 = np.random.rand(32, 64) - 0.5  # W3: (32 satÄ±r, 64 sÃ¼tun)\n",
    "    b3 = np.random.rand(32, 1) - 0.5   # b3: (32 satÄ±r, 1 sÃ¼tun)\n",
    "    \n",
    "    # ðŸ‘‰ Ã‡Ä±kÄ±ÅŸ KatmanÄ±: 32 nÃ¶ronu 10 nihai cevaba (0'dan 9'a) baÄŸlar\n",
    "    W4 = np.random.rand(10, 32) - 0.5  # W4: (10 satÄ±r, 32 sÃ¼tun)\n",
    "    b4 = np.random.rand(10, 1) - 0.5   # b4: (10 satÄ±r, 1 sÃ¼tun)\n",
    "    \n",
    "    # TÃ¼m bu parÃ§alarÄ± fonksiyonun sonucu olarak geri gÃ¶nder.\n",
    "    return W1, b1, W2, b2, W3, b3, W4, b4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d381d5",
   "metadata": {},
   "source": [
    "# Yapay Sinir AÄŸÄ± EÄŸitim DÃ¶ngÃ¼sÃ¼ (Forward & Backward)\n",
    "\n",
    "## 1\\. Ä°leri YayÄ±lÄ±m (Forward Propagation)\n",
    "\n",
    "Ä°leri YayÄ±lÄ±m, verinin **aÄŸÄ±n baÅŸÄ±ndan (giriÅŸ)** sonuna **(tahmin)** doÄŸru tek yÃ¶nlÃ¼ hareketidir. Bu aÅŸamada model, elindeki aÄŸÄ±rlÄ±klarÄ± kullanarak tahmin yapar.\n",
    "\n",
    "  * **AmaÃ§:** GiriÅŸ resmini ($X$) alÄ±p, katmanlar aracÄ±lÄ±ÄŸÄ±yla iÅŸleyerek nihai tahmini (Softmax Ã§Ä±ktÄ±sÄ± $a4$) Ã¼retmektir.\n",
    "  * **AdÄ±mlar:** Her katmanda iki temel iÅŸlem yapÄ±lÄ±r:\n",
    "    1.  **AÄŸÄ±rlÄ±klÄ± Toplam ($z$):** GiriÅŸler, aÄŸÄ±rlÄ±klarla Ã§arpÄ±lÄ±p sapma ($b$) eklenir. ($W \\cdot A + b$)\n",
    "    2.  **Aktivasyon ($a$):** $z$ sonucu, bir sonraki katmana gitmeden Ã¶nce ReLU (ve son katmanda Softmax) fonksiyonundan geÃ§irilir.\n",
    "\n",
    "-----\n",
    "\n",
    "## 2\\. Geri YayÄ±lÄ±m (Backward Propagation)\n",
    "\n",
    "Geri YayÄ±lÄ±m, modelin yaptÄ±ÄŸÄ± hatayÄ± bularak bu hatanÄ±n **aÄŸÄ±n sonundan (tahmin)** baÅŸÄ±na doÄŸru geri yayÄ±lmasÄ±dÄ±r. Bu, modelin hangi aÄŸÄ±rlÄ±klarÄ± ne kadar deÄŸiÅŸtirmesi gerektiÄŸini belirler.\n",
    "\n",
    "  * **AmaÃ§:** Tahmin edilen deÄŸer ($a4$) ile doÄŸru etiket ($Y$) arasÄ±ndaki farkÄ± (hata/gradyan) hesaplamak ve bu farkÄ± her katmanÄ±n aÄŸÄ±rlÄ±klarÄ±na daÄŸÄ±tmaktÄ±r.\n",
    "  * **AdÄ±mlar:**\n",
    "    1.  Son katmanda hata ($dz4$) hesaplanÄ±r: $\\text{Tahmin} - \\text{GerÃ§ek Etiket}$.\n",
    "    2.  Hata, zincirleme kuralÄ± kullanÄ±larak geriye doÄŸru her katmana iletilir ($dz3, dz2, dz1$).\n",
    "    3.  Her katmanda, aÄŸÄ±rlÄ±klarÄ±n ($dW$) ve sapmalarÄ±n ($db$) ne kadar deÄŸiÅŸmesi gerektiÄŸi hesaplanÄ±r.\n",
    "\n",
    "-----\n",
    "\n",
    "## 3\\. Parametre GÃ¼ncelleme (Update Parameters)\n",
    "\n",
    "Bu son adÄ±mda, Geri YayÄ±lÄ±m ile hesaplanan gradyanlar ($dW$ ve $db$) kullanÄ±larak aÄŸÄ±n aÄŸÄ±rlÄ±klarÄ± ve sapmalarÄ± gerÃ§ekten deÄŸiÅŸtirilir. Bu, aÄŸÄ±n **Ã¶ÄŸrenme** eylemidir.\n",
    "\n",
    "  * **AmaÃ§:** AÄŸÄ±rlÄ±klarÄ±, hatayÄ± azaltacak yÃ¶nde kÃ¼Ã§Ã¼k adÄ±mlarla deÄŸiÅŸtirmektir.\n",
    "  * **Ã–ÄŸrenme OranÄ± ($\\alpha$):** DeÄŸiÅŸimin ne kadar hÄ±zlÄ± (bÃ¼yÃ¼k adÄ±mlarla) yapÄ±lacaÄŸÄ±nÄ± kontrol eden Ã¶nemli bir ayardÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f493f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W1, b1, W2, b2, W3, b3, W4, b4, X):\n",
    "    # Katman 1\n",
    "    z1 = W1.dot(X) + b1\n",
    "    a1 = relu(z1)\n",
    "    \n",
    "    # Katman 2\n",
    "    z2 = W2.dot(a1) + b2\n",
    "    a2 = relu(z2)\n",
    "    \n",
    "    # Katman 3\n",
    "    z3 = W3.dot(a2) + b3\n",
    "    a3 = relu(z3)\n",
    "    \n",
    "    # Katman 4 (Ã‡Ä±kÄ±ÅŸ)\n",
    "    z4 = W4.dot(a3) + b4 # W4 * A3 + B4\n",
    "    a4 = softmax(z4)     # Z4'Ã¼ (aÄŸÄ±rlÄ±klÄ± toplam) Softmax'e vermeliyiz\n",
    "\n",
    "    return z1, a1, z2, a2, z3, a3, z4, a4\n",
    "\n",
    "def backward_prop(z1, a1, z2, a2, z3, a3, z4, a4, W1, W2, W3, W4, X, Y):\n",
    "    # m, Ã¶rnek sayÄ±sÄ±dÄ±r\n",
    "    _, m = X.shape\n",
    "    one_hot_Y = one_hot(Y) # one_hot fonksiyonunuzun tanÄ±mlÄ± olduÄŸunu varsayÄ±yorum\n",
    "\n",
    "    # Katman 4 -> Katman 3\n",
    "    dz4 = a4 - one_hot_Y\n",
    "    # HATA DÃœZELTÄ°LDÄ°: dW4 iÃ§in A3 kullanÄ±lmalÄ±\n",
    "    dw4 = 1 / m * dz4.dot(a3.T)\n",
    "    # Ä°YÄ°LEÅžTÄ°RME: db4 iÃ§in boyut korumasÄ± eklendi\n",
    "    db4 = 1 / m * np.sum(dz4, axis=1, keepdims=True)\n",
    "\n",
    "    # Katman 3 -> Katman 2\n",
    "    dz3 = W4.T.dot(dz4) * relu_deriv(z3)\n",
    "    dw3 = 1 / m * dz3.dot(a2.T)\n",
    "    db3 = 1 / m * np.sum(dz3, axis=1, keepdims=True)\n",
    "\n",
    "    # Katman 2 -> Katman 1\n",
    "    dz2 = W3.T.dot(dz3) * relu_deriv(z2)\n",
    "    # HATA DÃœZELTÄ°LDÄ°: dw2 iÃ§in A1 kullanÄ±lmalÄ± (Bu zaten doÄŸruydu, bir Ã¶nceki kontrol hataydÄ±, ama burada L1 aktivasyonu doÄŸru)\n",
    "    dw2 = 1 / m * dz2.dot(a1.T) \n",
    "    db2 = 1 / m * np.sum(dz2, axis=1, keepdims=True)\n",
    "\n",
    "    # Katman 1 -> GiriÅŸ (X=A0)\n",
    "    dz1 = W2.T.dot(dz2) * relu_deriv(z1)\n",
    "    dw1 = 1 / m * dz1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dz1, axis=1, keepdims=True)\n",
    "\n",
    "    return dw1, db1, dw2, db2, dw3, db3, dw4, db4\n",
    "\n",
    "def update_params(W1, b1, W2, b2, W3, b3, W4, b4, dw1, db1, dw2, db2, dw3, db3, dw4, db4, alpha):\n",
    "    # Gizli Katman 1 (W1, b1) gÃ¼ncelleniyor:\n",
    "    # AÄŸÄ±rlÄ±k W1, Ã¶ÄŸrenme oranÄ± (alpha) * gradyan (dw1) kadar azaltÄ±lÄ±r.\n",
    "    W1 = W1 - alpha * dw1\n",
    "    # Sapma b1, Ã¶ÄŸrenme oranÄ± (alpha) * gradyan (db1) kadar azaltÄ±lÄ±r.\n",
    "    b1 = b1 - alpha * db1\n",
    "\n",
    "    # Gizli Katman 2 (W2, b2) gÃ¼ncelleniyor:\n",
    "    W2 = W2 - alpha * dw2\n",
    "    b2 = b2 - alpha * db2\n",
    "    \n",
    "    # Gizli Katman 3 (W3, b3) gÃ¼ncelleniyor:\n",
    "    W3 = W3 - alpha * dw3\n",
    "    b3 = b3 - alpha * db3\n",
    "\n",
    "    # Ã‡Ä±kÄ±ÅŸ KatmanÄ± (W4, b4) gÃ¼ncelleniyor:\n",
    "    W4 = W4 - alpha * dw4\n",
    "    b4 = b4 - alpha * db4\n",
    "\n",
    "    # TÃ¼m gÃ¼ncellenmiÅŸ parametreleri dÃ¶ndÃ¼r.\n",
    "    return W1, b1, W2, b2, W3, b3, W4, b4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222a6a5",
   "metadata": {},
   "source": [
    "# Temel Fonksiyonlar ve EÄŸitim Ã‡ekirdeÄŸi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    # Gizli Katman 1: 784 -> 128\n",
    "    W1 = np.random.rand(128, 784) - 0.5\n",
    "    b1 = np.random.rand(128, 1) - 0.5\n",
    "    \n",
    "    # Gizli Katman 2: 128 -> 64\n",
    "    W2 = np.random.rand(64, 128) - 0.5\n",
    "    b2 = np.random.rand(64, 1) - 0.5\n",
    "    \n",
    "    # Gizli Katman 3: 64 -> 32\n",
    "    W3 = np.random.rand(32, 64) - 0.5\n",
    "    b3 = np.random.rand(32, 1) - 0.5\n",
    "    \n",
    "    # Ã‡Ä±kÄ±ÅŸ KatmanÄ±: 32 -> 10\n",
    "    W4 = np.random.rand(10, 32) - 0.5\n",
    "    b4 = np.random.rand(10, 1) - 0.5\n",
    "    \n",
    "    return W1, b1, W2, b2, W3, b3, W4, b4\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(X, 0)\n",
    "\n",
    "def relu_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def softmax(X):\n",
    "    e_x = np.exp(X - np.max(X))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, W3, b3, W4, b4, X):\n",
    "    # Katman 1\n",
    "    z1 = W1.dot(X) + b1\n",
    "    a1 = relu(z1)\n",
    "    \n",
    "    # Katman 2\n",
    "    z2 = W2.dot(a1) + b2\n",
    "    a2 = relu(z2)\n",
    "    \n",
    "    # Katman 3\n",
    "    z3 = W3.dot(a2) + b3\n",
    "    a3 = relu(z3)\n",
    "    \n",
    "    # Katman 4 (Ã‡Ä±kÄ±ÅŸ)\n",
    "    z4 = W4.dot(a3) + b4 # W4 * A3 + B4\n",
    "    a4 = softmax(z4)     # Z4'Ã¼ (aÄŸÄ±rlÄ±klÄ± toplam) Softmax'e vermeliyiz\n",
    "\n",
    "    return z1, a1, z2, a2, z3, a3, z4, a4\n",
    "\n",
    "def one_hot(Y):\n",
    "    # 1. SÄ±fÄ±rlardan oluÅŸan bir matris oluÅŸtur\n",
    "    # (Y.size: Ã¶rnek sayÄ±sÄ±, Y.max() + 1: sÄ±nÄ±f sayÄ±sÄ± (0'dan baÅŸladÄ±ÄŸÄ± iÃ§in +1))\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    \n",
    "    # 2. KarÅŸÄ±lÄ±k gelen sÃ¼tunlara 1 deÄŸerini atama\n",
    "    # Y.size: tÃ¼m satÄ±rlarÄ± seÃ§\n",
    "    # Y: her satÄ±r iÃ§in hangi sÃ¼tunun 1 olacaÄŸÄ±nÄ± belirler\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    \n",
    "    # 3. BoyutlarÄ± sinir aÄŸÄ±na uygun hale getirme (Transpoze)\n",
    "    # (SÄ±nÄ±f sayÄ±sÄ± x Ã–rnek sayÄ±sÄ±\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "\n",
    "    return one_hot_Y\n",
    "\n",
    "def backward_prop(z1, a1, z2, a2, z3, a3, z4, a4, W1, W2, W3, W4, X, Y):\n",
    "    # m, Ã¶rnek sayÄ±sÄ±dÄ±r\n",
    "    _, m = X.shape\n",
    "    one_hot_Y = one_hot(Y) # one_hot fonksiyonunuzun tanÄ±mlÄ± olduÄŸunu varsayÄ±yorum\n",
    "\n",
    "    # Katman 4 -> Katman 3\n",
    "    dz4 = a4 - one_hot_Y\n",
    "    # HATA DÃœZELTÄ°LDÄ°: dW4 iÃ§in A3 kullanÄ±lmalÄ±\n",
    "    dw4 = 1 / m * dz4.dot(a3.T)\n",
    "    # Ä°YÄ°LEÅžTÄ°RME: db4 iÃ§in boyut korumasÄ± eklendi\n",
    "    db4 = 1 / m * np.sum(dz4, axis=1, keepdims=True)\n",
    "\n",
    "    # Katman 3 -> Katman 2\n",
    "    dz3 = W4.T.dot(dz4) * relu_deriv(z3)\n",
    "    dw3 = 1 / m * dz3.dot(a2.T)\n",
    "    db3 = 1 / m * np.sum(dz3, axis=1, keepdims=True)\n",
    "\n",
    "    # Katman 2 -> Katman 1\n",
    "    dz2 = W3.T.dot(dz3) * relu_deriv(z2)\n",
    "    # HATA DÃœZELTÄ°LDÄ°: dw2 iÃ§in A1 kullanÄ±lmalÄ± (Bu zaten doÄŸruydu, bir Ã¶nceki kontrol hataydÄ±, ama burada L1 aktivasyonu doÄŸru)\n",
    "    dw2 = 1 / m * dz2.dot(a1.T) \n",
    "    db2 = 1 / m * np.sum(dz2, axis=1, keepdims=True)\n",
    "\n",
    "    # Katman 1 -> GiriÅŸ (X=A0)\n",
    "    dz1 = W2.T.dot(dz2) * relu_deriv(z1)\n",
    "    dw1 = 1 / m * dz1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dz1, axis=1, keepdims=True)\n",
    "\n",
    "    return dw1, db1, dw2, db2, dw3, db3, dw4, db4\n",
    "\n",
    "def update_params(W1, b1, W2, b2, W3, b3, W4, b4, dw1, db1, dw2, db2, dw3, db3, dw4, db4, alpha):\n",
    "    # Gizli Katman 1 (W1, b1) gÃ¼ncelleniyor:\n",
    "    # AÄŸÄ±rlÄ±k W1, Ã¶ÄŸrenme oranÄ± (alpha) * gradyan (dw1) kadar azaltÄ±lÄ±r.\n",
    "    W1 = W1 - alpha * dw1\n",
    "    # Sapma b1, Ã¶ÄŸrenme oranÄ± (alpha) * gradyan (db1) kadar azaltÄ±lÄ±r.\n",
    "    b1 = b1 - alpha * db1\n",
    "\n",
    "    # Gizli Katman 2 (W2, b2) gÃ¼ncelleniyor:\n",
    "    W2 = W2 - alpha * dw2\n",
    "    b2 = b2 - alpha * db2\n",
    "    \n",
    "    # Gizli Katman 3 (W3, b3) gÃ¼ncelleniyor:\n",
    "    W3 = W3 - alpha * dw3\n",
    "    b3 = b3 - alpha * db3\n",
    "\n",
    "    # Ã‡Ä±kÄ±ÅŸ KatmanÄ± (W4, b4) gÃ¼ncelleniyor:\n",
    "    W4 = W4 - alpha * dw4\n",
    "    b4 = b4 - alpha * db4\n",
    "\n",
    "    # TÃ¼m gÃ¼ncellenmiÅŸ parametreleri dÃ¶ndÃ¼r.\n",
    "    return W1, b1, W2, b2, W3, b3, W4, b4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b02d9",
   "metadata": {},
   "source": [
    "# Sinir AÄŸÄ±nÄ±n Ã–ÄŸrenme YÃ¶netimi: Gradyan Ä°niÅŸi\n",
    "\n",
    "Bu kod bloÄŸu, modelin tahmin yapmasÄ±ndan Ã¶ÄŸrenme dÃ¶ngÃ¼sÃ¼nÃ¼n yÃ¶netimine kadar tÃ¼m sÃ¼reci kapsar:\n",
    "\n",
    "* **Tahmin Ã‡Ä±karma (`get_predictions`):**\n",
    "    * Modelin Softmax'ten aldÄ±ÄŸÄ± olasÄ±lÄ±k puanlarÄ± arasÄ±ndan **en yÃ¼ksek olana sahip olanÄ±** nihai tahmin olarak seÃ§er.\n",
    "\n",
    "* **BaÅŸarÄ± Ã–lÃ§Ã¼mÃ¼ (`get_accuracy`):**\n",
    "    * YapÄ±lan tahminleri, gerÃ§ek cevaplarla karÅŸÄ±laÅŸtÄ±rÄ±r ve modelin **doÄŸruluk yÃ¼zdesini** hesaplar. Bu, Ã¶ÄŸrenmenin ne kadar baÅŸarÄ±lÄ± olduÄŸunu gÃ¶sterir.\n",
    "\n",
    "* **Ana EÄŸitim DÃ¶ngÃ¼sÃ¼ (`gradient_descent`):**\n",
    "    * TÃ¼m sÃ¼reci yÃ¶neten ana fonksiyondur.\n",
    "    * Ä°lk olarak rastgele aÄŸÄ±rlÄ±klarÄ± (`init_params`) baÅŸlatÄ±r.\n",
    "    * Belirlenen tekrar sayÄ±sÄ± boyunca sÃ¼rekli olarak:\n",
    "        * **Ä°leri YayÄ±lÄ±m** ile tahmin yapar.\n",
    "        * **Geri YayÄ±lÄ±m** ile hatayÄ± bulup dÃ¼zeltme miktarÄ±nÄ± hesaplar.\n",
    "        * **Parametre GÃ¼ncelleme** ile aÄŸÄ±rlÄ±klarÄ± dÃ¼zelterek modeli geliÅŸtirir.\n",
    "\n",
    "Bu dÃ¶ngÃ¼, modelin hata yapa yapa Ã¶ÄŸrenmesini saÄŸlayan **Gradyan Ä°niÅŸi** algoritmasÄ±nÄ± uygular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7765291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(a4):\n",
    "    return np.argmax(a4, 0)\n",
    "\n",
    "def get_accuracy(p, Y):\n",
    "    print(p, Y)\n",
    "    return np.sum(p == Y) /Y.size\n",
    "\n",
    "def gradient_descent(X, Y, iterations, alpha):\n",
    "\n",
    "    W1, b1, W2, b2, W3, b3, W4, b4 = init_params()\n",
    "\n",
    "    for i in range(iterations):\n",
    "        z1, a1, z2, a2, z3, a3, z4, a4 = forward_prop(W1, b1, W2, b2, W3, b3, W4, b4, X)\n",
    "        dw1, db1, dw2, db2, dw3, db3, dw4, db4 = backward_prop(z1, a1, z2, a2, z3, a3, z4, a4, W1, W2, W3, W4, X, Y)\n",
    "        W1, b1, W2, b2, W3, b3, W4, b4 = update_params(W1, b1, W2, b2, W3, b3, W4, b4, dw1, db1, dw2, db2, dw3, db3, dw4, db4, alpha)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            print(\"Accuracy: \",  get_accuracy(get_predictions(a4), Y))\n",
    "        \n",
    "    return W1, b1, W2, b2, W3, b3, W4, b4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e9da5",
   "metadata": {},
   "source": [
    "# EÄŸitimi BaÅŸlatma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2, W3, b3, W4, b4 = gradient_descent(x_train, y_train, 500 ,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f1741",
   "metadata": {},
   "source": [
    "# Tek Tek Tahminleri GÃ¶rme ve GÃ¶rselleÅŸtirme:\n",
    "\n",
    "Bu kod, eÄŸitilmiÅŸ sinir aÄŸÄ±nÄ±n test verisi Ã¼zerinde **canlÄ± performansÄ±nÄ±** gÃ¶rmeye yarar.\n",
    "\n",
    "1.  **`make_predictions`:** SeÃ§ilen **tek bir resim** Ã¼zerinde ileri yayÄ±lÄ±m (`forward_prop`) yaparak tahmin Ã¼retir ve bu resmi, **gerÃ§ek etiketi** ile **modelin tahminini** yan yana gÃ¶steren bir grafik olarak Ã§izer.\n",
    "2.  **DÃ¶ngÃ¼ (`for`):** Bu fonksiyonu art arda Ã§alÄ±ÅŸtÄ±rarak, modelin **ilk birkaÃ§ resimdeki** tahminini sÄ±rayla ekranda sergiler. Her resmi gÃ¶sterdikten sonra kÄ±sa bir sÃ¼re bekler.\n",
    "\n",
    "**AmaÃ§:** Modelin ne Ã¶ÄŸrendiÄŸini ve hatalarÄ±nÄ± (varsa) gÃ¶rsel olarak anÄ±nda kontrol etmektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f20422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_predictions(X_data, index, W1, b1, W2, b2, W3, b3, W4, b4, y_train):\n",
    "    X_single = X_data[:, index, None] \n",
    "        \n",
    "    _, _, _, _, _, _, _, A4 = forward_prop(W1, b1, W2, b2, W3, b3, W4, b4, X_single)\n",
    "    prediction = np.argmax(A4, 0) \n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    image_to_show = X_single.reshape((28, 28)) * 255\n",
    "    \n",
    "    plt.gray()\n",
    "    plt.imshow(image_to_show, interpolation='nearest')\n",
    "    plt.title(f\"GerÃ§ek Etiket: {y_train[index]} | Tahmin: {prediction[0]}\") \n",
    "    plt.axis('off')\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "i = 10\n",
    "for i in range(i):\n",
    "    \n",
    "    clear_output(wait=True) \n",
    "    gercek_etiket = y_train[i]\n",
    "    \n",
    "    tahmin = make_predictions(x_train, i, W1, b1, W2, b2, W3, b3, W4, b4, y_train)\n",
    "    \n",
    "    display(plt.gcf())\n",
    "    plt.close()\n",
    "    time.sleep(2)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc15dcc7",
   "metadata": {},
   "source": [
    "# MLP SÄ±nÄ±fÄ±: Neden SÄ±nÄ±f TabanlÄ± YapÄ± KullanÄ±ldÄ±?\n",
    "\n",
    "Bu kod bloÄŸu, daha Ã¶nceki parÃ§a parÃ§a fonksiyonlarÄ± (`forward_prop`, `backward_prop` vb.) tek bir **`mlp` (Ã‡ok KatmanlÄ± AlgÄ±layÄ±cÄ±)** **SÄ±nÄ±fÄ±** altÄ±nda toplayan, organize ve profesyonel bir yapÄ±dÄ±r.\n",
    "\n",
    "## Bu YapÄ±nÄ±n Eski Fonksiyonlardan FarkÄ± ve GeliÅŸtirilen YÃ¶nleri\n",
    "\n",
    "### 1. Esneklik: Ä°stenen SayÄ±da Katman OluÅŸturma\n",
    "\n",
    "* **Ã–nceki Kod:** Gizli katman sayÄ±sÄ± (W1, W2, W3, W4) **sabit** ve kod iÃ§ine elle yazÄ±lmÄ±ÅŸtÄ±.\n",
    "* **SÄ±nÄ±f Kodunuz:** **Gizli katman sayÄ±sÄ±nÄ± istediÄŸiniz gibi ayarlayabilirsiniz** (`hidding_layer_size` parametresi). `params` metodu, bu sayÄ±ya gÃ¶re gerekli tÃ¼m aÄŸÄ±rlÄ±k ve sapmalarÄ± (`self.weight`, `self.bias` listeleri) otomatik olarak oluÅŸturur. Bu, kodu Ã¶nemli Ã¶lÃ§Ã¼de esnek yapar.\n",
    "\n",
    "### 2. Otomatik YÃ¶netim ve Temizlik \n",
    "\n",
    "* **Ã–nceki Kod:** `forward_prop` gibi fonksiyonlara her seferinde tÃ¼m aÄŸÄ±rlÄ±klarÄ± tek tek (W1, b1, W2, b2, ...) gÃ¶ndermeniz gerekiyordu.\n",
    "* **SÄ±nÄ±f Kodunuz:** TÃ¼m aÄŸÄ±rlÄ±klar ve ara sonuÃ§lar (`self.weight`, `self.activated_output`) sÄ±nÄ±fÄ±n iÃ§inde saklanÄ±r. Metotlar (`forward_prop`, `backward_prop`) bu deÄŸiÅŸkenlere doÄŸrudan eriÅŸir, bu sayede fonksiyon Ã§aÄŸrÄ±larÄ± Ã§ok daha temiz ve basitleÅŸir.\n",
    "\n",
    "### 3. Tek Ã‡atÄ± AltÄ±nda EÄŸitim (`train`)\n",
    "\n",
    "* Modelin kurulumu, eÄŸitimi ve tahmin yapmasÄ± (baÅŸlangÄ±Ã§tan sona kadar tÃ¼m adÄ±mlar) tek bir **`mlp` nesnesi** tarafÄ±ndan yÃ¶netilir.\n",
    "* **`train()`** metodunu Ã§aÄŸÄ±rmanÄ±z, modelin Ã¶ÄŸrenmesi iÃ§in yeterlidir; tÃ¼m ileri yayÄ±lÄ±m, hata hesaplama ve dÃ¼zeltme adÄ±mlarÄ± otomatik olarak Ã§alÄ±ÅŸÄ±r.\n",
    "\n",
    "**Ã–zetle:** SÄ±nÄ±f yapÄ±sÄ±, modeli sadece Ã§alÄ±ÅŸtÄ±ran fonksiyonlar olmaktan Ã§Ä±karÄ±p, **kendi kendine yeten, esnek katmanlÄ± ve yÃ¶netilebilir bir Yapay Zeka Nesnesine** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp:\n",
    "\n",
    "    def __init__(self, x_train, y_train, hidding_layer_size, epoch ,lr):\n",
    "\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.hidding_layer_size = hidding_layer_size\n",
    "        self.epoch = epoch\n",
    "        self.lr = lr\n",
    "\n",
    "        self.weight = []\n",
    "        self.dWeight = []\n",
    "        self.bias = []\n",
    "        self.dbias = []\n",
    "        self.linear_output = []\n",
    "        self.activated_output = []\n",
    "        self.accuracies = []\n",
    "\n",
    "        self.params()\n",
    "\n",
    "    def relu(self, X):\n",
    "        return np.maximum(X, 0)\n",
    "\n",
    "    def relu_deriv(self, Z):\n",
    "        return (Z > 0).astype(float)\n",
    "\n",
    "\n",
    "    def softmax(self, X):\n",
    "        e_x = np.exp(X - np.max(X, axis=0, keepdims=True))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "    \n",
    "    def one_hot(self, Y):\n",
    "        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "        one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "        return one_hot_Y.T\n",
    "\n",
    "    def params(self):\n",
    "\n",
    "        input_size = self.x_train.shape[0]\n",
    "        output_size = len(np.unique(self.y_train))\n",
    "\n",
    "        H_max = int(2 ** np.floor(np.log2(input_size))) \n",
    "        H_hesaplanan = 32 * (2 ** (self.hidding_layer_size - 1))\n",
    "        H_start = min(H_hesaplanan, H_max) \n",
    "\n",
    "        for _ in range(self.hidding_layer_size):\n",
    "            self.weight.append(np.random.randn(H_start, input_size) * np.sqrt(2 / input_size)) \n",
    "            self.bias.append(np.zeros((H_start, 1)))\n",
    "\n",
    "            input_size = H_start\n",
    "            H_start = max(16, int(H_start / 2)) \n",
    "\n",
    "        self.weight.append(np.random.randn(output_size, input_size) * np.sqrt(2 / input_size)) \n",
    "        self.bias.append(np.zeros((output_size, 1)))\n",
    "\n",
    "    def forward_prop(self,):\n",
    "        X = self.x_train\n",
    "        self.linear_output = []\n",
    "        self.activated_output = []\n",
    "\n",
    "        for i in range(len(self.weight)):\n",
    "            z = self.weight[i].dot(X) + self.bias[i]\n",
    "            self.linear_output.append(z)\n",
    "            X = self.softmax(z) if i == len(self.weight) - 1 else self.relu(z)\n",
    "            self.activated_output.append(X)\n",
    "\n",
    "    def backward_prop(self):\n",
    "        _, m = self.x_train.shape\n",
    "        dz_ = self.activated_output[-1] - self.one_hot(self.y_train)\n",
    "\n",
    "        self.dWeight = [None] * len(self.weight)\n",
    "        self.dbias = [None] * len(self.bias)\n",
    "\n",
    "        for i in reversed(range(len(self.weight))):\n",
    "            a_prev = self.x_train if i == 0 else self.activated_output[i-1]\n",
    "\n",
    "            self.dWeight[i] = 1 / m * dz_.dot(a_prev.T)\n",
    "            self.dbias[i] = 1 / m * np.sum(dz_, axis=1, keepdims=True)\n",
    "\n",
    "            if i != 0:\n",
    "                dz_ = self.weight[i].T.dot(dz_) * self.relu_deriv(self.linear_output[i-1])\n",
    "\n",
    "    def update_params(self):\n",
    "        for i in range(len(self.weight)):\n",
    "            self.weight[i] = self.weight[i] - self.lr * self.dWeight[i]\n",
    "            self.bias[i] = self.bias[i] - self.lr * self.dbias[i]\n",
    "\n",
    "    def get_accuracy(self):\n",
    "        p = np.argmax(self.activated_output[-1] , 0)\n",
    "        Y = self.y_train\n",
    "        return np.mean(p == Y)\n",
    "\n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            self.forward_prop()\n",
    "            self.backward_prop()\n",
    "            self.update_params()\n",
    "            if i % 10 == 0:\n",
    "                acc = self.get_accuracy()\n",
    "                self.accuracies.append(acc)\n",
    "                print(f\"Iteration: {i}, Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    def make_predictions(self, num_samples=10):\n",
    "        for i in range(num_samples):\n",
    "            X = self.x_train[:, i, None]\n",
    "            for j in range(len(self.weight)):\n",
    "                z = self.weight[j].dot(X) + self.bias[j]\n",
    "                X = self.softmax(z) if j == len(self.weight) - 1 else self.relu(z)\n",
    "            pred = np.argmax(X, 0)[0]\n",
    "\n",
    "            plt.imshow(self.x_train[:, i].reshape(28, 28), cmap='gray')\n",
    "            plt.title(f\"GerÃ§ek: {self.y_train[i]} | Tahmin: {pred}\")\n",
    "            plt.axis('off')\n",
    "            clear_output(wait=True)\n",
    "            display(plt.gcf())\n",
    "            plt.close()\n",
    "            time.sleep(1)\n",
    "             \n",
    "a = mlp(x_train, y_train, 5, 250, 0.01)\n",
    "a.train()\n",
    "a.make_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
